{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-19T16:04:08.169070Z","iopub.status.busy":"2023-10-19T16:04:08.168437Z","iopub.status.idle":"2023-10-19T16:05:01.361255Z","shell.execute_reply":"2023-10-19T16:05:01.360154Z","shell.execute_reply.started":"2023-10-19T16:04:08.169043Z"},"trusted":true},"outputs":[],"source":["!pip install torch==2.0.0\n","!pip install pytorch_lightning==2.1.0\n","!pip install transformers==4.34.1\n","!pip install datasets==2.1.0\n","!pip install torchmetrics==1.2.0"]},{"cell_type":"code","execution_count":14,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-19T16:48:42.209350Z","iopub.status.busy":"2023-10-19T16:48:42.209056Z","iopub.status.idle":"2023-10-19T16:52:20.554182Z","shell.execute_reply":"2023-10-19T16:52:20.553395Z","shell.execute_reply.started":"2023-10-19T16:48:42.209328Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9da7d029d3d24eb986d947cc3379ab06","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab1021de424a4664be52632349efe0bb","version_major":2,"version_minor":0},"text/plain":["Testing: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.061837393790483475    </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.183049738407135     </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.061837393790483475    </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5726782083511353     </span>│\n","└───────────────────────────┴───────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.061837393790483475   \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m        test_mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.183049738407135    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.061837393790483475   \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5726782083511353    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[{'test_loss': 0.061837393790483475,\n","  'test_mse': 0.061837393790483475,\n","  'test_r2': 0.5726782083511353,\n","  'test_mae': 0.183049738407135}]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["import pytorch_lightning as pl\n","import torchmetrics\n","import torch\n","import datasets\n","import torch.nn.functional as F\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup, AdamW\n","from torch.utils.data import DataLoader\n","from transformers import DataCollatorWithPadding\n","\n","BATCH_SIZE_TRAIN = 16\n","BATCH_SIZE_EVAL = 16\n","NUM_EPOCH = 5\n","LEARNING_RATE = 2e-5\n","WARM_UP_STEPS = 400\n","\n","# Load the dataset\n","dataset = datasets.load_dataset('google_wellformed_query')\n","\n","# Tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","    \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        inputs = tokenizer(item['content'], truncation=True, padding=False, return_tensors='pt')\n","        return {'input_ids': inputs['input_ids'].squeeze(), 'attention_mask': inputs['attention_mask'].squeeze(), 'labels': item['rating']}\n","\n","class CustomModel(pl.LightningModule):\n","    def __init__(self, data_module):\n","        super().__init__()\n","        self.model = AutoModelForSequenceClassification.from_pretrained('distilroberta-base')\n","        self.regression_head = torch.nn.Linear(self.model.config.hidden_size, 1)\n","        self.data_module = data_module\n","        \n","        # Instantiate metrics\n","        self.train_mse = torchmetrics.MeanSquaredError()\n","        self.val_mse = torchmetrics.MeanSquaredError()\n","        self.test_mse = torchmetrics.MeanSquaredError()\n","        \n","        self.train_r2 = torchmetrics.R2Score()\n","        self.val_r2 = torchmetrics.R2Score()\n","        self.test_r2 = torchmetrics.R2Score()\n","        \n","        self.train_mae = torchmetrics.MeanAbsoluteError()\n","        self.val_mae = torchmetrics.MeanAbsoluteError()\n","        self.test_mae = torchmetrics.MeanAbsoluteError()\n","\n","    def forward(self, input_ids, attention_mask, **kwargs):\n","        outputs = self.model.base_model(input_ids=input_ids, attention_mask=attention_mask)\n","        rating = self.regression_head(outputs.last_hidden_state[:, 0, :])\n","        rating = F.sigmoid(rating)\n","        return rating.squeeze()\n","    \n","    def training_step(self, batch, batch_idx):\n","        outputs = self(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n","        loss = torch.nn.functional.mse_loss(outputs, batch['labels'])\n","        self.log('train_loss', loss)\n","        self.train_mse(outputs, batch['labels'])\n","        self.train_r2(outputs, batch['labels'])\n","        self.train_mae(outputs, batch['labels'])\n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx):\n","        outputs = self(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n","        loss = torch.nn.functional.mse_loss(outputs, batch['labels'])\n","        self.log('val_loss', loss)\n","        self.val_mse(outputs, batch['labels'])\n","        self.val_r2(outputs, batch['labels'])\n","        self.val_mae(outputs, batch['labels'])\n","\n","    def test_step(self, batch, batch_idx):\n","        outputs = self(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n","        loss = torch.nn.functional.mse_loss(outputs, batch['labels'])\n","        self.log('test_loss', loss)\n","        self.test_mse(outputs, batch['labels'])\n","        self.test_r2(outputs, batch['labels'])\n","        self.test_mae(outputs, batch['labels'])\n","        return {'test_loss': loss} \n","    \n","    def configure_optimizers(self):\n","        optimizer = AdamW(self.parameters(), lr=LEARNING_RATE)\n","        steps_per_epoch = len(self.data_module.train_dataset) // BATCH_SIZE_TRAIN\n","        total_steps = steps_per_epoch * NUM_EPOCH\n","        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARM_UP_STEPS, num_training_steps=total_steps)\n","        return [optimizer], [{'scheduler': scheduler, 'interval': 'step'}]\n","\n","    def on_validation_epoch_end(self):\n","        self.log('val_mse', self.val_mse.compute(), prog_bar=True)\n","        self.log('val_r2', self.val_r2.compute(), prog_bar=True)\n","        self.log('val_mae', self.val_mae.compute(), prog_bar=True)\n","        \n","        # don't forget to reset at the end of epoch\n","        self.val_mse.reset()\n","        self.val_r2.reset()\n","        self.val_mae.reset()\n","\n","    def on_test_epoch_end(self):\n","        self.log('test_mse', self.test_mse.compute(), prog_bar=True)\n","        self.log('test_r2', self.test_r2.compute(), prog_bar=True)\n","        self.log('test_mae', self.test_mae.compute(), prog_bar=True)\n","        \n","        # don't forget to reset at the end of epoch\n","        self.test_mse.reset()\n","        self.test_r2.reset()\n","        self.test_mae.reset()\n","    \n","class CustomDataModule(pl.LightningDataModule):\n","    def __init__(self, dataset, tokenizer):\n","        super().__init__()\n","        self.dataset = dataset\n","        self.tokenizer = tokenizer\n","        self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n","    \n","    def setup(self, stage=None):\n","        self.train_dataset = CustomDataset(self.dataset['train'])\n","        self.val_dataset = CustomDataset(self.dataset['validation'])\n","        self.test_dataset = CustomDataset(self.dataset['test'])\n","    \n","    def train_dataloader(self):\n","        return DataLoader(self.train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, collate_fn=self.data_collator)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.val_dataset, batch_size=BATCH_SIZE_EVAL, collate_fn=self.data_collator)\n","    \n","    def test_dataloader(self):\n","        return DataLoader(self.test_dataset, batch_size=BATCH_SIZE_EVAL, collate_fn=self.data_collator)\n","\n","# Initialize data module, model, and trainer\n","data_module = CustomDataModule(dataset, tokenizer)\n","model = CustomModel(data_module=data_module)\n","trainer = pl.Trainer(max_epochs=NUM_EPOCH,accelerator=\"auto\")\n","\n","# Train the model\n","trainer.fit(model, data_module)\n","\n","# Evaluate the model on the test dataset\n","trainer.test(datamodule=data_module)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-10-19T16:52:37.688817Z","iopub.status.busy":"2023-10-19T16:52:37.688521Z","iopub.status.idle":"2023-10-19T16:52:38.771480Z","shell.execute_reply":"2023-10-19T16:52:38.770607Z","shell.execute_reply.started":"2023-10-19T16:52:37.688795Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving the model...\n"]},{"data":{"text/plain":["('/kaggle/working/new/tokenizer_config.json',\n"," '/kaggle/working/new/special_tokens_map.json',\n"," '/kaggle/working/new/vocab.json',\n"," '/kaggle/working/new/merges.txt',\n"," '/kaggle/working/new/added_tokens.json',\n"," '/kaggle/working/new/tokenizer.json')"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["print(\"Saving the model...\")\n","model.model.save_pretrained(\"/kaggle/working/new\")\n","\n","# Save the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n","tokenizer_save_path = \"/kaggle/working/new\"\n","tokenizer.save_pretrained(tokenizer_save_path)\n","\n","# Save the regression head\n","torch.save(model.regression_head.state_dict(), f\"/kaggle/working/new/regression_head.pth\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-10-19T16:52:20.555780Z","iopub.status.busy":"2023-10-19T16:52:20.555527Z","iopub.status.idle":"2023-10-19T16:52:20.611096Z","shell.execute_reply":"2023-10-19T16:52:20.610259Z","shell.execute_reply.started":"2023-10-19T16:52:20.555752Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: The cat and dog in the yard.\n","Predicted Rating: 0.2043018490076065\n","\n","Sentence: she don't like apples.\n","Predicted Rating: 0.08289707452058792\n","\n","Sentence: Is rain sunny days sometimes?\n","Predicted Rating: 0.20011107623577118\n","\n","Sentence: She enjoys reading books and playing chess.\n","Predicted Rating: 0.8915352821350098\n","\n","Sentence: How many planets are there in our solar system?\n","Predicted Rating: 0.974799394607544\n","\n"]},{"data":{"text/plain":["\"Sentence: The cat and dog in the yard.\\nPredicted Rating: 0.3482873737812042\\n\\nSentence: she don't like apples.\\nPredicted Rating: 0.07787154614925385\\n\\nSentence: Is rain sunny days sometimes?\\nPredicted Rating: 0.19854165613651276\\n\\nSentence: She enjoys reading books and playing chess.\\nPredicted Rating: 0.9327691793441772\\n\\nSentence: How many planets are there in our solar system?\\nPredicted Rating: 0.9746372103691101\\n\""]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Sentences\n","sentences = [\n","    \"The cat and dog in the yard.\",  # Incorrect - It should be \"The cat and dog are in the yard.\"\n","    \"she don't like apples.\",  # Incorrect - It should be \"She doesn't like apples.\"\n","    \"Is rain sunny days sometimes?\",  # Incorrect - It should be \"Do sunny days sometimes have rain?\"\n","    \"She enjoys reading books and playing chess.\",  # Correct\n","    \"How many planets are there in our solar system?\"  # Correct\n","]\n","\n","# Tokenizing the sentences\n","inputs = tokenizer(sentences, truncation=True, padding=True, return_tensors='pt')\n","\n","# Getting the model's predictions\n","with torch.no_grad():  # Disabling gradient calculation as we are only doing inference\n","    model.eval()  # Setting the model to evaluation mode\n","    predicted_ratings = model(\n","        input_ids=inputs['input_ids'], \n","        attention_mask=inputs['attention_mask']\n","    )\n","\n","# The predicted_ratings is a tensor, so we'll convert it to a list of standard Python numbers\n","predicted_ratings = predicted_ratings.squeeze().tolist()\n","\n","# Printing the predicted ratings\n","for i, rating in enumerate(predicted_ratings):\n","    print(f'Sentence: {sentences[i]}')\n","    print(f'Predicted Rating: {rating}\\n')\n","\n","#Reference\n","'''Sentence: The cat and dog in the yard.\n","Predicted Rating: 0.20430190861225128\n","\n","Sentence: she don't like apples.\n","Predicted Rating: 0.08289700001478195\n","\n","Sentence: Is rain sunny days sometimes?\n","Predicted Rating: 0.20011138916015625\n","\n","Sentence: She enjoys reading books and playing chess.\n","Predicted Rating: 0.8915354013442993\n","\n","Sentence: How many planets are there in our solar system?\n","Predicted Rating: 0.974799394607544\n","'''"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
